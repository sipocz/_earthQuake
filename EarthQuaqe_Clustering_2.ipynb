{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EarthQuaqe_Clustering_2.ipynb",
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyNmJRT/Wf4uVHNCjGoZFE3m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sipocz/_earthQuake/blob/main/EarthQuaqe_Clustering_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c58B1xuLnyms",
        "outputId": "1f7201de-4222-4041-c430-908b8fbab150"
      },
      "source": [
        "#EarthQuake\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#import sweetviz as sw\n",
        "\n",
        "#!pip install sweetviz\n",
        "#import sweetviz as sw\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SkJx-von7P6"
      },
      "source": [
        "df=pd.read_csv(\"/content/drive/My Drive/001_AI/_EarthQuake/features_a.csv\")\n",
        "df_clasters=pd.read_csv(\"/content/drive/My Drive/001_AI/_EarthQuake/train_labels.csv\")\n",
        "df_testvalues=pd.read_csv(\"/content/drive/My Drive/001_AI/_EarthQuake/test_a.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AbxPEhnn8x_"
      },
      "source": [
        "numx=110000\n",
        "Y=df_clasters[[\"damage_grade\"]]\n",
        "X=df\n",
        "scaler=MinMaxScaler()\n",
        "Xt=X[:numx]\n",
        "Xt=scaler.fit_transform(Xt)\n",
        "Xt=Xt[:numx]\n",
        "Y=Y[[\"damage_grade\"]]\n",
        "Y=Y[:numx]\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xt, Y, random_state=0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzn2G8tyooH8",
        "outputId": "b13003d8-4fae-449a-c7c1-c52896ad6fed"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
        "     .format(knn.score(X_train, y_train)))\n",
        "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
        "     .format(knn.score(X_test,y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UktGrK05Grf"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j__RaxKOx3lb"
      },
      "source": [
        "df_testvalues"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6LSAL8AyGlG"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Sl4yUp_3_6j"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMgY6h-E4Ya1"
      },
      "source": [
        "df_testvalues"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8C90QAi5_qR"
      },
      "source": [
        "a=['geo_level_1_id', 'geo_level_2_id', 'count_floors_pre_eq', 'age',\n",
        "       'area_percentage', 'height_percentage', 'has_superstructure_adobe_mud',\n",
        "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
        "       'has_superstructure_cement_mortar_stone',\n",
        "       'has_superstructure_mud_mortar_brick',\n",
        "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
        "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
        "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
        "       'count_families', 'has_secondary_use', 'has_secondary_use_agriculture',\n",
        "       'has_secondary_use_hotel', 'has_secondary_use_rental',\n",
        "       'has_secondary_use_institution', 'has_secondary_use_school',\n",
        "       'has_secondary_use_industry', 'has_secondary_use_other',\n",
        "       'land_surface_condition_t', 'land_surface_condition_o',\n",
        "       'foundation_type_h', 'foundation_type_w', 'foundation_type_i',\n",
        "       'foundation_type_r', 'foundation_type_u', 'roof_type_q', 'roof_type_n',\n",
        "       'roof_type_x', 'ground_floor_type_z', 'ground_floor_type_v',\n",
        "       'ground_floor_type_f', 'ground_floor_type_m', 'other_floor_type_q',\n",
        "       'other_floor_type_s', 'other_floor_type_j', 'other_floor_type_x',\n",
        "       'position_j', 'position_s', 'position_t', 'plan_configuration_c',\n",
        "       'plan_configuration_s', 'plan_configuration_d', 'plan_configuration_a',\n",
        "       'plan_configuration_u', 'plan_configuration_o',\n",
        "       'legal_ownership_status_a', 'legal_ownership_status_w',\n",
        "       'legal_ownership_status_v']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-TRLfpx7Tyl"
      },
      "source": [
        "b=[\"geo_level_1_id\",\"geo_level_2_id\",\"count_floors_pre_eq\",\"age\",\"area_percentage\",\"height_percentage\",\"has_superstructure_adobe_mud\",\"has_superstructure_mud_mortar_stone\",\"has_superstructure_stone_flag\",\"has_superstructure_cement_mortar_stone\",\"has_superstructure_mud_mortar_brick\",\"has_superstructure_cement_mortar_brick\",\"has_superstructure_timber\",\"has_superstructure_bamboo\",\"has_superstructure_rc_non_engineered\",\"has_superstructure_rc_engineered\",\"has_superstructure_other\",\"count_families\",\"has_secondary_use\",\"has_secondary_use_agriculture\",\"has_secondary_use_hotel\",\"has_secondary_use_rental\",\"has_secondary_use_institution\",\"has_secondary_use_school\",\"has_secondary_use_industry\",\"has_secondary_use_other\",\"land_surface_condition_t\",\"land_surface_condition_o\",\"foundation_type_h\",\"foundation_type_w\",\"foundation_type_i\",\"foundation_type_r\",\"foundation_type_u\",\"roof_type_q\",\"roof_type_n\",\"roof_type_x\",\"ground_floor_type_z\",\"ground_floor_type_v\",\"ground_floor_type_f\",\"ground_floor_type_m\",\"other_floor_type_q\",\"other_floor_type_s\",\"other_floor_type_j\",\"other_floor_type_x\",\"position_j\",\"position_s\",\"position_t\",\"plan_configuration_c\",\"plan_configuration_s\",\"plan_configuration_d\",\"plan_configuration_a\",\"plan_configuration_u\",\"plan_configuration_o\",\"legal_ownership_status_a\",\"legal_ownership_status_w\",\"legal_ownership_status_v\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA7cCkEu8lJp"
      },
      "source": [
        "print(len(b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_gsg_RM6tni"
      },
      "source": [
        "df_testvalues"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPpcdm5e6ib5"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-nU0qra6lAQ"
      },
      "source": [
        "df_testvalues[a]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzvMjz5h6E5F"
      },
      "source": [
        "\n",
        "df_testvalues"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LXHj4Gswc8o"
      },
      "source": [
        "df_testvalues=scaler.fit_transform(df_testvalues)\n",
        "Ypredikt=knn.predict(df_testvalues)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_qK36psxf6Y"
      },
      "source": [
        "Ypredikt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo-kFO1isX13"
      },
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train, y_train)\n",
        "print('Accuracy of LDA classifier on training set: {:.2f}'\n",
        "     .format(lda.score(X_train, y_train)))\n",
        "print('Accuracy of LDA classifier on test set: {:.2f}'\n",
        "     .format(lda.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z3dZqdFsdXX"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "print('Accuracy of GNB classifier on training set: {:.2f}'\n",
        "     .format(gnb.score(X_train, y_train)))\n",
        "print('Accuracy of GNB classifier on test set: {:.2f}'\n",
        "     .format(gnb.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXV3iE_PsiF6"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
        "     .format(svm.score(X_train, y_train)))\n",
        "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
        "     .format(svm.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJaxv7l55zXY"
      },
      "source": [
        "a=['geo_level_1_id', 'geo_level_2_id', 'count_floors_pre_eq', 'age',\n",
        "       'area_percentage', 'height_percentage', 'has_superstructure_adobe_mud',\n",
        "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
        "       'has_superstructure_cement_mortar_stone',\n",
        "       'has_superstructure_mud_mortar_brick',\n",
        "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
        "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
        "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
        "       'count_families', 'has_secondary_use', 'has_secondary_use_agriculture',\n",
        "       'has_secondary_use_hotel', 'has_secondary_use_rental',\n",
        "       'has_secondary_use_institution', 'has_secondary_use_school',\n",
        "       'has_secondary_use_industry', 'has_secondary_use_other',\n",
        "       'land_surface_condition_t', 'land_surface_condition_o',\n",
        "       'foundation_type_h', 'foundation_type_w', 'foundation_type_i',\n",
        "       'foundation_type_r', 'foundation_type_u', 'roof_type_q', 'roof_type_n',\n",
        "       'roof_type_x', 'ground_floor_type_z', 'ground_floor_type_v',\n",
        "       'ground_floor_type_f', 'ground_floor_type_m', 'other_floor_type_q',\n",
        "       'other_floor_type_s', 'other_floor_type_j', 'other_floor_type_x',\n",
        "       'position_j', 'position_s', 'position_t', 'plan_configuration_c',\n",
        "       'plan_configuration_s', 'plan_configuration_d', 'plan_configuration_a',\n",
        "       'plan_configuration_u', 'plan_configuration_o',\n",
        "       'legal_ownership_status_a', 'legal_ownership_status_w',\n",
        "       'legal_ownership_status_v']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWsfT5xW53AA"
      },
      "source": [
        "X_test="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ZNmqvzsm02"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "pred = knn.predict(X_test)\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI3BdQFDs7wa"
      },
      "source": [
        "Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk6aHWCLrqTm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNlcQ1v-sTiZ"
      },
      "source": [
        "df=pd.read_csv(\"/content/drive/My Drive/001_AI/_EarthQuake/test_values.csv\")\n",
        "def checkvalues(columnname,key):\n",
        "    print(f\"{columnname} ellenőrzése !\")\n",
        "    numok=0\n",
        "    numerr=0\n",
        "    for i in df.index:\n",
        "        if df.at[i,columnname] in key:\n",
        "            #print(df.at[i,columnname])\n",
        "            numok+=1\n",
        "            pass\n",
        "        else:\n",
        "            numerr+=1\n",
        "            print(df.at[i,columnname],end=\", \")\n",
        "    sumall=numok+numerr\n",
        "    print(f\"\\n{sumall} mintából {numerr} db nem volt megfelelő\")\n",
        "\n",
        "\n",
        "def createcolumn(columnname,keys):\n",
        "    for key in keys:\n",
        "        df[keys[key]]=0.0\n",
        "    for key in keys:\n",
        "        for i in df.index:\n",
        "            if df.at[i,columnname]==key:\n",
        "                df.at[i,keys[key]]=1.0\n",
        "\n",
        "\n",
        "def create_dict(idx,list):\n",
        "    o={}\n",
        "    for i in list:\n",
        "        o[i]=idx+\"_\"+i\n",
        "    return o\n",
        "\n",
        "t=['n', 't', 'o']\n",
        "columnname=\"land_surface_condition\"\n",
        "key=create_dict(columnname,t)\n",
        "\n",
        "checkvalues(columnname,key)\n",
        "createcolumn(columnname,key)\n",
        "\n",
        "t= ['h', 'w', 'i', 'r', 'u']\n",
        "columnname=\"foundation_type\"\n",
        "key=create_dict(columnname,t)\n",
        "\n",
        "checkvalues(columnname,key)\n",
        "createcolumn(columnname,key)\n",
        "\n",
        "t=  ['q', 'n', 'x']\n",
        "columnname=\"roof_type\"\n",
        "key=create_dict(columnname,t)\n",
        "\n",
        "checkvalues(columnname,key)\n",
        "createcolumn(columnname,key)\n",
        "\n",
        "t=  ['z', 'v', 'f', 'm', 'x']\n",
        "columnname=\"ground_floor_type\"\n",
        "key=create_dict(columnname,t)\n",
        "\n",
        "checkvalues(columnname,key)\n",
        "createcolumn(columnname,key)\n",
        "\n",
        "t=   ['q', 's', 'j', 'x']\n",
        "columnname=\"other_floor_type\"\n",
        "key=create_dict(columnname,t)\n",
        "\n",
        "checkvalues(columnname,key)\n",
        "createcolumn(columnname,key)\n",
        "\n",
        "t=   ['j', 's', 't', 'o']\n",
        "columnname=\"position\"\n",
        "key=create_dict(columnname,t)\n",
        "\n",
        "checkvalues(columnname,key)\n",
        "createcolumn(columnname,key)\n",
        "\n",
        "t=   ['c', 's', 'f', 'd', 'm', 'a', 'q', 'u', 'n', 'o']\n",
        "columnname=\"plan_configuration\"\n",
        "key=create_dict(columnname,t)\n",
        "\n",
        "checkvalues(columnname,key)\n",
        "createcolumn(columnname,key)\n",
        "\n",
        "\n",
        "t=['a', 'w', 'r', 'v']\n",
        "columnname=\"legal_ownership_status\"\n",
        "key=create_dict(columnname,t)\n",
        "\n",
        "checkvalues(columnname,key)\n",
        "createcolumn(columnname,key)\n",
        "\n",
        "\n",
        "t=['a', 'w', 'r', 'v']\n",
        "columnname=\"legal_ownership_status\"\n",
        "key=create_dict(columnname,t)\n",
        "\n",
        "checkvalues(columnname,key)\n",
        "createcolumn(columnname,key)\n",
        "\n",
        "\n",
        "nlarge=list((ColListF+ColListA))\n",
        "# ha összefűződik a 2 lista lehet, hogy benne van a SalePrice is. Az NAGYON nem jó\n",
        "if \"damage_grade\" in nlarge[1:]:\n",
        "    print(\"damage_grade a fedélzeten :-( \")\n",
        "\n",
        "\n",
        "print(nlarge)\n",
        "print(len(nlarge))\n",
        "\n",
        "\n",
        "for i in df.columns:\n",
        "    if i not in nlarge:\n",
        "        df.drop(columns=[i], inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}